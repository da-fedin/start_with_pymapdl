{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbb88596",
   "metadata": {},
   "source": [
    "# Lesson 4 - Dataset Pools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84226cf9cdd17fb0",
   "metadata": {},
   "source": [
    "Make imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b4cdff21751b5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T10:46:04.099616Z",
     "start_time": "2024-06-07T10:46:02.697901Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from ansys.mapdl.core import MapdlPool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40958919c3ea82e2",
   "metadata": {},
   "source": [
    "Create several onstances of mapdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f360c-5ae7-4ef3-8d45-3442b079028d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T10:46:13.442178Z",
     "start_time": "2024-06-07T10:46:04.099616Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize 3 instances of mapdl running on 8 processors in SMP mode\n",
    "pool = MapdlPool(n_instances=3, nproc=8, additional_switches=\"-smp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe340436edbaf59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T10:46:13.453627Z",
     "start_time": "2024-06-07T10:46:13.442178Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set mapdl model as a function\n",
    "def model(mapdl, load_x_inches, load_y_inches):\n",
    "    \"\"\"\n",
    "    Get mapdl model as a function to interact with pool\n",
    "    \"\"\"\n",
    "    # Set run counter\n",
    "    run_number = 0\n",
    "\n",
    "    run_number += 1\n",
    "\n",
    "    print(f\"Start model: {run_number}\")\n",
    "\n",
    "    # Define area length and width\n",
    "    length_inches = 4.5\n",
    "    height_inches = 2\n",
    "\n",
    "    # Define position of sensors and first load as a dictionary\n",
    "    sensors = {\n",
    "        \"x1\": 1,\n",
    "        \"y1\": 0.5,\n",
    "        \"x2\": 2.25,\n",
    "        \"y2\": 0.5,\n",
    "        \"x3\": 3.5,\n",
    "        \"y3\": 0.5,\n",
    "        \"x4\": 1,\n",
    "        \"y4\": 1.5,\n",
    "        \"x5\": 2.25,\n",
    "        \"y5\": 1.5,\n",
    "        \"x6\": 3.5,\n",
    "        \"y6\": 1.5,\n",
    "        \"x7\": 0.5,\n",
    "        \"y7\": 1,\n",
    "        \"x8\": 4,\n",
    "        \"y8\": 1,\n",
    "        \"load_x\": load_x_inches,\n",
    "        \"load_y\": load_y_inches,\n",
    "    }\n",
    "\n",
    "    # Set sensors data as empty dictionary\n",
    "    sensors_data = {}\n",
    "\n",
    "    # Create rectangular area\n",
    "    # Clear model\n",
    "    mapdl.clear()\n",
    "\n",
    "    # Enter pre-processor\n",
    "    mapdl.prep7()\n",
    "\n",
    "    # Create a rectangular area or block volume by corner points\n",
    "    mapdl.blc4(0, 0, length_inches, height_inches, 0)\n",
    "\n",
    "    # Delete un-meshed areas\n",
    "    mapdl.adele(\"all\")\n",
    "\n",
    "    # Generate a fillet line between two intersecting lines\n",
    "    mapdl.lfillt(1, 2, 0.2)\n",
    "    mapdl.lfillt(2, 3, 0.2)\n",
    "    mapdl.lfillt(3, 4, 0.2)\n",
    "    mapdl.lfillt(4, 1, 0.2)\n",
    "\n",
    "    # Compress the numbering of defined items\n",
    "    mapdl.numcmp(\"area\")\n",
    "\n",
    "    # Generate an area bounded by previously defined lines\n",
    "    mapdl.al(\"all\")\n",
    "\n",
    "    # Define hard points by sensor coordinates\n",
    "    for points in range(1, (int((len(sensors) - 2) / 2)) + 1):\n",
    "        mapdl.hptcreate(\n",
    "            type_=\"area\",\n",
    "            entity=1,\n",
    "            nhp=\"\",\n",
    "            label=\"coord\",\n",
    "            val1=sensors[\"x\" + str(points)],\n",
    "            val2=sensors[\"y\" + str(points)],\n",
    "            val3=0,\n",
    "        )\n",
    "\n",
    "    # Define hard point by load coordinates\n",
    "    mapdl.hptcreate(\"area\", 1, \"\", \"coord\", sensors[\"load_x\"], sensors[\"load_y\"], 0)\n",
    "\n",
    "    # Merges coincident or equivalently defined items\n",
    "    mapdl.nummrg(\"kp\")\n",
    "\n",
    "    # Set material properties\n",
    "    mapdl.mp(\"ex\", 1, 1e7)\n",
    "\n",
    "    # Set element type\n",
    "    mapdl.et(1, 181)\n",
    "\n",
    "    # Set section type (shell representation)\n",
    "    mapdl.sectype(1, \"shell\")\n",
    "\n",
    "    # Set shell thickness\n",
    "    mapdl.secdata(0.1, 1)\n",
    "\n",
    "    # Specify the element shape as 2D\n",
    "    mapdl.mshape(1, \"2d\")\n",
    "\n",
    "    # Specify the element size to be meshed onto areas\n",
    "    mapdl.smrtsize(3)\n",
    "\n",
    "    # Generate nodes and area elements within areas\n",
    "    mapdl.amesh(\"all\")\n",
    "\n",
    "    # Loop over nodes where sensors located\n",
    "    for points in range(1, (int((len(sensors) - 2) / 2)) + 1):\n",
    "        node = mapdl.queries.node(\n",
    "            sensors[\"x\" + str(points)], sensors[\"y\" + str(points)], 0\n",
    "        )\n",
    "\n",
    "        # Refine the mesh around specified nodes\n",
    "        mapdl.nrefine(node, level=2, depth=1)\n",
    "\n",
    "    # Unselect nodes\n",
    "    mapdl.nsel(\"none\")\n",
    "\n",
    "    # Set component with selected nodes\n",
    "    mapdl.cm(\"sensors\", \"node\")\n",
    "\n",
    "    # Select all entities\n",
    "    mapdl.allsel()\n",
    "\n",
    "    # Loop over nodes where sensors located again\n",
    "    for points in range(1, (int((len(sensors) - 2) / 2)) + 1):\n",
    "        # Get node\n",
    "        node = mapdl.queries.node(\n",
    "            sensors[\"x\" + str(points)], sensors[\"y\" + str(points)], 0\n",
    "        )\n",
    "\n",
    "        # Select a new set named \"sensors\"\n",
    "        mapdl.cmsel(\"s\", \"sensors\")\n",
    "\n",
    "        # Additionally select current node\n",
    "        mapdl.nsel(\"a\", \"node\", \"\", node)\n",
    "\n",
    "        # Group components into new component\n",
    "        mapdl.cm(\"sensors\", \"node\")\n",
    "\n",
    "        # Select all entities\n",
    "        mapdl.allsel()\n",
    "\n",
    "    # Exit normally from a processor\n",
    "    mapdl.finish()\n",
    "\n",
    "    # Enter solution settings\n",
    "    mapdl.slashsolu()\n",
    "\n",
    "    # Define DOF constraints on lines???\n",
    "    mapdl.dl(\"all\", \"\", \"all\", 0)\n",
    "\n",
    "    # Get node to apply force\n",
    "    force_node = mapdl.queries.node(sensors[\"load_x\"], sensors[\"load_y\"], 0)\n",
    "\n",
    "    # Apply force to node\n",
    "    mapdl.f(force_node, \"fz\", 1)\n",
    "\n",
    "    # Set solution as non-linear\n",
    "    mapdl.nlgeom(\"on\")\n",
    "\n",
    "    # Solve solution\n",
    "    mapdl.solve()\n",
    "    # solve = mapdl.solve()\n",
    "\n",
    "    # Exit normally from a processor\n",
    "    mapdl.finish()\n",
    "    # Enter post-processor\n",
    "    mapdl.post1()\n",
    "\n",
    "    # Set last time step/set as current\n",
    "    mapdl.set(\"last\")\n",
    "\n",
    "    # Select all entities\n",
    "    mapdl.allsel()\n",
    "\n",
    "    # Set result as empty dictionary\n",
    "    result = {}\n",
    "\n",
    "    # Fill dictionary with load values\n",
    "    result[\"Load_X\"] = sensors[\"load_x\"]\n",
    "    result[\"Load_Y\"] = sensors[\"load_y\"]\n",
    "\n",
    "    # Loop over nodes of sensors\n",
    "    for points in range(1, (int((len(sensors) - 2) / 2)) + 1):\n",
    "        # Set node\n",
    "        node = mapdl.queries.node(\n",
    "            sensors[\"x\" + str(points)], sensors[\"y\" + str(points)], 0\n",
    "        )\n",
    "\n",
    "        # Get x-component of total strain in node\n",
    "        strain_x = mapdl.get_value(\"node\", node, \"epto\", \"x\")\n",
    "\n",
    "        # Get y-component of total strain in node\n",
    "        strain_y = mapdl.get_value(\"node\", node, \"epto\", \"y\")\n",
    "\n",
    "        # Write data to result dictionary\n",
    "        result[\"Strn_X_\" + str(points)] = strain_x\n",
    "        result[\"Strn_Y_\" + str(points)] = strain_y\n",
    "\n",
    "    print(\"End run\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf7c60f589dddad",
   "metadata": {},
   "source": [
    "Gether results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5620cf3a31b196",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T10:46:13.465069Z",
     "start_time": "2024-06-07T10:46:13.453627Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set input data as empty list\n",
    "inputs = []\n",
    "\n",
    "# Set path to file\n",
    "result_path = r\"tmp\\point_set.csv\"\n",
    "\n",
    "# Set path to save data\n",
    "save_path = os.path.join(os.path.dirname(os.getcwd()), result_path)\n",
    "\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f743662cb332104c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T10:46:13.472033Z",
     "start_time": "2024-06-07T10:46:13.466584Z"
    }
   },
   "outputs": [],
   "source": [
    "# Open the file in read mode and create a CSV reader object\n",
    "with open(save_path, newline=\"\") as csvfile:\n",
    "    point_reader = csv.reader(csvfile, delimiter=\",\", quotechar=\"|\")\n",
    "\n",
    "    # Loop over each row in the CSV file\n",
    "    for point in point_reader:\n",
    "        # Convert each point to a tuple of floats and add it to the inputs list\n",
    "        inputs.append((float(point[0]), float(point[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef8d7f30335e923",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T10:46:13.481861Z",
     "start_time": "2024-06-07T10:46:13.476412Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Write strain data to file\n",
    "# with open(file=save_path, newline=\"\", mode='r') as csvfile:\n",
    "#     point_input = csv.writer(csvfile, delimiter=\",\", quotechar=\"|\")\n",
    "#\n",
    "#     # Loop over\n",
    "#     for point in point_input:\n",
    "#         inputs += [(float(point[0]), float(point[1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d8845843d42fee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T10:46:13.489758Z",
     "start_time": "2024-06-07T10:46:13.481861Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set header for dataframe object\n",
    "header = {\n",
    "    \"Load_X\": [],\n",
    "    \"Load_Y\": [],\n",
    "    \"Strn_X_1\": [],\n",
    "    \"Strn_Y_1\": [],\n",
    "    \"Strn_X_2\": [],\n",
    "    \"Strn_Y_2\": [],\n",
    "    \"Strn_X_3\": [],\n",
    "    \"Strn_Y_3\": [],\n",
    "    \"Strn_X_4\": [],\n",
    "    \"Strn_Y_4\": [],\n",
    "    \"Strn_X_5\": [],\n",
    "    \"Strn_Y_5\": [],\n",
    "    \"Strn_X_6\": [],\n",
    "    \"Strn_Y_6\": [],\n",
    "    \"Strn_X_7\": [],\n",
    "    \"Strn_Y_7\": [],\n",
    "    \"Strn_X_8\": [],\n",
    "    \"Strn_Y_8\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e77910e38d12bec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T10:46:13.502527Z",
     "start_time": "2024-06-07T10:46:13.489758Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set dataset with only header\n",
    "result_dataset = pd.DataFrame(data=header)\n",
    "\n",
    "result_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18070be0-969e-400b-a383-7982aa48ab04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T10:46:32.012186Z",
     "start_time": "2024-06-07T10:46:13.502527Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Start solution -------\")\n",
    "\n",
    "# Run a function for each instance of mapdl within the pool, get list of function results\n",
    "output = pool.map(func=model, iterable=inputs, progress_bar=True, wait=True)\n",
    "\n",
    "# Set dummy dataset with only output\n",
    "dummy_dataset = pd.DataFrame(data=output)\n",
    "\n",
    "# Concatenate datasets to get dataset with results\n",
    "result_dataset = pd.concat([result_dataset, dummy_dataset], ignore_index=True)\n",
    "\n",
    "print(\"End solution\")\n",
    "\n",
    "# Show dataset\n",
    "result_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8b83320119d35d",
   "metadata": {},
   "source": [
    "Serialize result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d49582-0580-4b97-ac5b-d9f2750ec6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set path to file\n",
    "# result_path = r\"tmp\\point_set.csv\"\n",
    "#\n",
    "# # Set path to save data\n",
    "# save_path = os.path.join(os.path.dirname(os.getcwd()), result_path)\n",
    "#\n",
    "# # Serialize result dataset to file\n",
    "# result_dataset.to_pickle(save_path)\n",
    "#\n",
    "# # Exit pool\n",
    "# pool.exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
