{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbb88596",
   "metadata": {},
   "source": [
    "# Lesson 4 - Dataset Pools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84226cf9cdd17fb0",
   "metadata": {},
   "source": [
    "Make imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b4cdff21751b5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:41:40.988270Z",
     "start_time": "2024-06-08T14:41:39.837643Z"
    }
   },
   "outputs": [],
   "source": [
    "from ansys.mapdl.core import launch_mapdl\n",
    "\n",
    "# For quite exiting on error\n",
    "from commons import StopExecution\n",
    "\n",
    "# To mute annoying warnings in notebook\n",
    "import warnings\n",
    "\n",
    "# Implement warning muting\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ansys.mapdl.core import MapdlPool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40958919c3ea82e2",
   "metadata": {},
   "source": [
    "Create several onstances of mapdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f360c-5ae7-4ef3-8d45-3442b079028d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:41:50.177089Z",
     "start_time": "2024-06-08T14:41:40.988270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize 3 instances of mapdl running on 8 processors in SMP mode\n",
    "pool = MapdlPool(\n",
    "    n_instances=3,\n",
    "    nproc=8,\n",
    "    additional_switches=\"-smp\",\n",
    "    override=True,\n",
    "    remove_temp_files=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f77d31ec11f213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:41:50.182522Z",
     "start_time": "2024-06-08T14:41:50.177089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define area length and width\n",
    "length_inches = 4.5\n",
    "height_inches = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f1baea667264fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:41:50.189139Z",
     "start_time": "2024-06-08T14:41:50.182522Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the ranges for the width and height\n",
    "width_start = 0.2\n",
    "width_end = 4.4\n",
    "height_start = 0.2\n",
    "height_end = 1.8\n",
    "step = 0.2\n",
    "\n",
    "# Generate the points\n",
    "x_values = np.arange(width_start, width_end + step, step)\n",
    "y_values = np.arange(height_start, height_end + step, step)\n",
    "\n",
    "# Create the grid of points\n",
    "grid_points = [[x, y] for x in x_values for y in y_values]\n",
    "\n",
    "print(f\"Number of runs: {len(grid_points)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c8741480b80dd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:41:50.194557Z",
     "start_time": "2024-06-08T14:41:50.189139Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define position of sensors and first load as a dictionary\n",
    "sensor_positions = {\n",
    "    \"sensor_1\": (1, 0.5),\n",
    "    \"sensor_2\": (2.25, 0.5),\n",
    "    \"sensor_3\": (3.5, 0.5),\n",
    "    \"sensor_4\": (1, 1.5),\n",
    "    \"sensor_5\": (2.25, 1.5),\n",
    "    \"sensor_6\": (3.5, 1.5),\n",
    "    \"sensor_7\": (0.5, 1),\n",
    "    \"sensor_8\": (4, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe340436edbaf59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:41:50.204951Z",
     "start_time": "2024-06-08T14:41:50.196637Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set mapdl model as a function\n",
    "def model(mapdl, load_x, load_y):\n",
    "    \"\"\"\n",
    "    Get mapdl model as a function to interact with pool\n",
    "    \"\"\"\n",
    "    # Clear model\n",
    "    mapdl.clear()\n",
    "\n",
    "    # -------------------------- GEOMETRY --------------------------\n",
    "    # Enter pre-processor\n",
    "    mapdl.prep7()\n",
    "\n",
    "    # Create a rectangular area or block volume by corner points\n",
    "    mapdl.blc4(0, 0, length_inches, height_inches, 0)\n",
    "\n",
    "    # Delete un-meshed areas\n",
    "    mapdl.adele(\"all\")\n",
    "\n",
    "    # Generate a fillet line between two intersecting lines\n",
    "    mapdl.lfillt(1, 2, 0.2)\n",
    "    mapdl.lfillt(2, 3, 0.2)\n",
    "    mapdl.lfillt(3, 4, 0.2)\n",
    "    mapdl.lfillt(4, 1, 0.2)\n",
    "\n",
    "    # Compress the numbering of defined items\n",
    "    mapdl.numcmp(\"area\")\n",
    "\n",
    "    # Generate an area bounded by previously defined lines\n",
    "    mapdl.al(\"all\")\n",
    "\n",
    "    # -------------------------- Material --------------------------\n",
    "    # Set material properties\n",
    "    mapdl.mp(\"ex\", 1, 1e7)\n",
    "\n",
    "    # -------------------------- Elements --------------------------\n",
    "\n",
    "    # Set section type (shell representation)\n",
    "    mapdl.sectype(1, \"shell\")\n",
    "\n",
    "    # Set shell thickness\n",
    "    mapdl.secdata(0.1, 1)\n",
    "\n",
    "    # Set element type\n",
    "    mapdl.et(1, 181)\n",
    "\n",
    "    # Define hard points by sensor coordinates\n",
    "    for sensor, position in sensor_positions.items():\n",
    "        x, y = position\n",
    "\n",
    "        mapdl.hptcreate(\n",
    "            type_=\"area\",\n",
    "            entity=1,\n",
    "            nhp=\"\",\n",
    "            label=\"coord\",\n",
    "            val1=x,\n",
    "            val2=y,\n",
    "            val3=0,\n",
    "        )\n",
    "\n",
    "    # Define hard point by load coordinates\n",
    "    mapdl.hptcreate(\n",
    "        type_=\"area\",\n",
    "        entity=1,\n",
    "        nhp=\"\",\n",
    "        label=\"coord\",\n",
    "        val1=load_x,\n",
    "        val2=load_y,\n",
    "        val3=0,\n",
    "    )\n",
    "\n",
    "    # Merges coincident or equivalently defined items\n",
    "    mapdl.nummrg(\"kp\")\n",
    "\n",
    "    # -------------------------- Mesh --------------------------\n",
    "    # Specify the element shape as 2D\n",
    "    mapdl.mshape(1, \"2d\")\n",
    "\n",
    "    # Specify the element size to be meshed onto areas\n",
    "    mapdl.aesize(\"all\", 0.1)\n",
    "\n",
    "    # Mesh model\n",
    "    mapdl.amesh(\"all\")\n",
    "\n",
    "    # Loop over nodes where sensors located\n",
    "    for sensor, position in sensor_positions.items():\n",
    "        x, y = position\n",
    "\n",
    "        node = mapdl.queries.node(x, y, 0)\n",
    "\n",
    "        # Refine the mesh around specified nodes\n",
    "        mapdl.nrefine(node, level=1, depth=1)\n",
    "\n",
    "    # Unselect nodes\n",
    "    mapdl.nsel(\"none\")\n",
    "\n",
    "    # Select all entities\n",
    "    mapdl.allsel()\n",
    "\n",
    "    # mapdl.eplot(vtk=True)\n",
    "\n",
    "    # Exit normally from a processor\n",
    "    mapdl.finish()\n",
    "\n",
    "    # -------------------------- Solution --------------------------\n",
    "    # Enter solution settings\n",
    "    mapdl.slashsolu()\n",
    "\n",
    "    # Define DOF constraints on lines???\n",
    "    mapdl.dl(\"all\", \"\", \"all\", 0)\n",
    "\n",
    "    # Get node to apply force\n",
    "    force_node = mapdl.queries.node(load_x, load_y, 0)\n",
    "\n",
    "    # Apply force to node\n",
    "    mapdl.f(force_node, \"fz\", 1)\n",
    "\n",
    "    # Set solution as non-linear\n",
    "    mapdl.nlgeom(\"on\")\n",
    "\n",
    "    # Solve solution\n",
    "    mapdl.solve()\n",
    "\n",
    "    # Exit normally from a processor\n",
    "    mapdl.finish()\n",
    "\n",
    "    # -------------------------- Post --------------------------\n",
    "    # Enter post-processor\n",
    "    mapdl.post1()\n",
    "\n",
    "    # Set last time step/set as current\n",
    "    mapdl.set(\"last\")\n",
    "\n",
    "    # Select all entities\n",
    "    mapdl.allsel()\n",
    "\n",
    "    # Set result as empty dictionary\n",
    "    result = {}\n",
    "\n",
    "    # Fill dictionary with load values\n",
    "    result[\"Load_X\"] = load_x\n",
    "    result[\"Load_Y\"] = load_y\n",
    "\n",
    "    # Loop over nodes of sensors\n",
    "    for position in sensor_positions:\n",
    "        # Set node\n",
    "        node = mapdl.queries.node(position[0], position[1], 0)\n",
    "\n",
    "        # Get x-component of total strain in node\n",
    "        strain_x = mapdl.get_value(\"node\", node, \"epto\", \"x\")\n",
    "\n",
    "        # Get y-component of total strain in node\n",
    "        strain_y = mapdl.get_value(\"node\", node, \"epto\", \"y\")\n",
    "\n",
    "        # Write data to result dictionary\n",
    "        result[\"Strn_X_\" + position] = strain_x\n",
    "        result[\"Strn_Y_\" + position] = strain_y\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f51ce9c127335",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:45:01.367182Z",
     "start_time": "2024-06-08T14:41:50.204951Z"
    }
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "# Run a function for each instance of mapdl within the pool, get list of function results\n",
    "output = pool.map(func=model, iterable=grid_points, progress_bar=True, wait=True)\n",
    "\n",
    "# except Exception:\n",
    "#     print(\"No MAPDL found. Terminating...\")\n",
    "#\n",
    "#     raise StopExecution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd8b4c61d15503",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d8845843d42fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set header for dataframe object\n",
    "header = {\n",
    "    \"Load_X\": [],\n",
    "    \"Load_Y\": [],\n",
    "    \"Strn_X_1\": [],\n",
    "    \"Strn_Y_1\": [],\n",
    "    \"Strn_X_2\": [],\n",
    "    \"Strn_Y_2\": [],\n",
    "    \"Strn_X_3\": [],\n",
    "    \"Strn_Y_3\": [],\n",
    "    \"Strn_X_4\": [],\n",
    "    \"Strn_Y_4\": [],\n",
    "    \"Strn_X_5\": [],\n",
    "    \"Strn_Y_5\": [],\n",
    "    \"Strn_X_6\": [],\n",
    "    \"Strn_Y_6\": [],\n",
    "    \"Strn_X_7\": [],\n",
    "    \"Strn_Y_7\": [],\n",
    "    \"Strn_X_8\": [],\n",
    "    \"Strn_Y_8\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43266249c41553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset with only header\n",
    "result_dataset = pd.DataFrame(data=header)\n",
    "\n",
    "result_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e5408e0b12ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dummy dataset with only output\n",
    "dummy_dataset = pd.DataFrame(data=output)\n",
    "\n",
    "# Concatenate datasets to get dataset with results\n",
    "result_dataset = pd.concat([result_dataset, dummy_dataset], ignore_index=True)\n",
    "\n",
    "print(\"End solution\")\n",
    "\n",
    "# Show dataset\n",
    "result_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf7c60f589dddad",
   "metadata": {},
   "source": [
    "Gather results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5620cf3a31b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set input data as empty list\n",
    "# inputs = []\n",
    "#\n",
    "# # Set path to file\n",
    "# result_path = r\"tmp\\point_set.csv\"\n",
    "#\n",
    "# # Set path to save data\n",
    "# save_path = os.path.join(os.path.dirname(os.getcwd()), result_path)\n",
    "#\n",
    "# save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e77910e38d12bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set dataset with only header\n",
    "# result_dataset = pd.DataFrame(data=header)\n",
    "#\n",
    "# result_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18070be0-969e-400b-a383-7982aa48ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Start solution -------\")\n",
    "#\n",
    "# # Run a function for each instance of mapdl within the pool, get list of function results\n",
    "# output = pool.map(func=model, iterable=inputs, progress_bar=True, wait=True)\n",
    "#\n",
    "# # Set dummy dataset with only output\n",
    "# dummy_dataset = pd.DataFrame(data=output)\n",
    "#\n",
    "# # Concatenate datasets to get dataset with results\n",
    "# result_dataset = pd.concat([result_dataset, dummy_dataset], ignore_index=True)\n",
    "#\n",
    "# print(\"End solution\")\n",
    "#\n",
    "# # Show dataset\n",
    "# result_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8b83320119d35d",
   "metadata": {},
   "source": [
    "Serialize result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d49582-0580-4b97-ac5b-d9f2750ec6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set path to file\n",
    "# result_path = r\"tmp\\point_set.csv\"\n",
    "#\n",
    "# # Set path to save data\n",
    "# save_path = os.path.join(os.path.dirname(os.getcwd()), result_path)\n",
    "#\n",
    "# # Serialize result dataset to file\n",
    "# result_dataset.to_pickle(save_path)\n",
    "#\n",
    "# # Exit pool\n",
    "# pool.exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
